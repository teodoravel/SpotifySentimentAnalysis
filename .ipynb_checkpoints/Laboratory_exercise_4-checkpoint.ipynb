{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7JOxuK9Jje2"
   },
   "source": [
    "# Laboratory exercise 4\n",
    "\n",
    "## Warm-Up Mode (2 points)\n",
    "\n",
    "**Task Description**  \n",
    "Using the given dataset, develop and implement **3** different neural networks to predict the **air quality level**. Each network should differ in the following ways:  \n",
    "\n",
    "- **layer configurations** - use different numbers and types of layers;\n",
    "- **activation functions** - try different activation functions;\n",
    "- **neurons per layer** - experiment with different numbers of neurons in each layer; and\n",
    "- **number of layers** - build networks with varying depths.\n",
    "\n",
    "After developing the models, evaluate and compare the performance of all **3** approaches.\n",
    "\n",
    "**About the Dataset**  \n",
    "This dataset focuses on air quality assessment across various regions. The dataset contains 5,000 samples and captures critical environmental and demographic factors that influence pollution levels.\n",
    "\n",
    "**Features**:  \n",
    "- **Temperature (°C)**: Average temperature of the region.  \n",
    "- **Humidity (%)**: Relative humidity recorded in the region.  \n",
    "- **PM2.5 Concentration (µg/m³)**: Levels of fine particulate matter.  \n",
    "- **PM10 Concentration (µg/m³)**: Levels of coarse particulate matter.  \n",
    "- **NO2 Concentration (ppb)**: Nitrogen dioxide levels.  \n",
    "- **SO2 Concentration (ppb)**: Sulfur dioxide levels.  \n",
    "- **CO Concentration (ppm)**: Carbon monoxide levels.  \n",
    "- **Proximity to Industrial Areas (km)**: Distance to the nearest industrial zone.  \n",
    "- **Population Density (people/km²)**: Number of people per square kilometer in the region.  \n",
    "\n",
    "**Target Variable**: **Air Quality**  \n",
    "- **Good**: Clean air with low pollution levels.  \n",
    "- **Moderate**: Acceptable air quality but with some pollutants present.  \n",
    "- **Poor**: Noticeable pollution that may cause health issues for sensitive groups.  \n",
    "- **Hazardous**: Highly polluted air posing serious health risks to the population.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For machine learning preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# For building neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Here are the first 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "      <th>Air Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.8</td>\n",
       "      <td>59.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.3</td>\n",
       "      <td>319</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.3</td>\n",
       "      <td>75.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6.0</td>\n",
       "      <td>611</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.1</td>\n",
       "      <td>74.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.2</td>\n",
       "      <td>619</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.15</td>\n",
       "      <td>11.1</td>\n",
       "      <td>551</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>70.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>12.7</td>\n",
       "      <td>303</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  PM2.5  PM10   NO2   SO2    CO  \\\n",
       "0         29.8      59.1    5.2  17.9  18.9   9.2  1.72   \n",
       "1         28.3      75.6    2.3  12.2  30.8   9.7  1.64   \n",
       "2         23.1      74.7   26.7  33.8  24.4  12.6  1.63   \n",
       "3         27.1      39.1    6.1   6.3  13.5   5.3  1.15   \n",
       "4         26.5      70.7    6.9  16.0  21.9   5.6  1.01   \n",
       "\n",
       "   Proximity_to_Industrial_Areas  Population_Density Air Quality  \n",
       "0                            6.3                 319    Moderate  \n",
       "1                            6.0                 611    Moderate  \n",
       "2                            5.2                 619    Moderate  \n",
       "3                           11.1                 551        Good  \n",
       "4                           12.7                 303        Good  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('pollution_dataset.csv')\n",
    "print(\"Dataset loaded. Here are the first 5 rows:\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Temperature                    5000 non-null   float64\n",
      " 1   Humidity                       5000 non-null   float64\n",
      " 2   PM2.5                          5000 non-null   float64\n",
      " 3   PM10                           5000 non-null   float64\n",
      " 4   NO2                            5000 non-null   float64\n",
      " 5   SO2                            5000 non-null   float64\n",
      " 6   CO                             5000 non-null   float64\n",
      " 7   Proximity_to_Industrial_Areas  5000 non-null   float64\n",
      " 8   Population_Density             5000 non-null   int64  \n",
      " 9   Air Quality                    5000 non-null   object \n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 390.8+ KB\n",
      "None\n",
      "\n",
      "Data Description:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.029020</td>\n",
       "      <td>70.056120</td>\n",
       "      <td>20.142140</td>\n",
       "      <td>30.218360</td>\n",
       "      <td>26.412100</td>\n",
       "      <td>10.014820</td>\n",
       "      <td>1.500354</td>\n",
       "      <td>8.425400</td>\n",
       "      <td>497.423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.720661</td>\n",
       "      <td>15.863577</td>\n",
       "      <td>24.554546</td>\n",
       "      <td>27.349199</td>\n",
       "      <td>8.895356</td>\n",
       "      <td>6.750303</td>\n",
       "      <td>0.546027</td>\n",
       "      <td>3.610944</td>\n",
       "      <td>152.754084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.400000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>-6.200000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.100000</td>\n",
       "      <td>58.300000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>69.800000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>80.300000</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>13.725000</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58.600000</td>\n",
       "      <td>128.100000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>315.800000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>957.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature     Humidity        PM2.5         PM10          NO2  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean     30.029020    70.056120    20.142140    30.218360    26.412100   \n",
       "std       6.720661    15.863577    24.554546    27.349199     8.895356   \n",
       "min      13.400000    36.000000     0.000000    -0.200000     7.400000   \n",
       "25%      25.100000    58.300000     4.600000    12.300000    20.100000   \n",
       "50%      29.000000    69.800000    12.000000    21.700000    25.300000   \n",
       "75%      34.000000    80.300000    26.100000    38.100000    31.900000   \n",
       "max      58.600000   128.100000   295.000000   315.800000    64.900000   \n",
       "\n",
       "               SO2           CO  Proximity_to_Industrial_Areas  \\\n",
       "count  5000.000000  5000.000000                    5000.000000   \n",
       "mean     10.014820     1.500354                       8.425400   \n",
       "std       6.750303     0.546027                       3.610944   \n",
       "min      -6.200000     0.650000                       2.500000   \n",
       "25%       5.100000     1.030000                       5.400000   \n",
       "50%       8.000000     1.410000                       7.900000   \n",
       "75%      13.725000     1.840000                      11.100000   \n",
       "max      44.900000     3.720000                      25.800000   \n",
       "\n",
       "       Population_Density  \n",
       "count         5000.000000  \n",
       "mean           497.423800  \n",
       "std            152.754084  \n",
       "min            188.000000  \n",
       "25%            381.000000  \n",
       "50%            494.000000  \n",
       "75%            600.000000  \n",
       "max            957.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking class distribution in 'Air Quality':\n",
      "Air Quality\n",
      "Good         2000\n",
      "Moderate     1500\n",
      "Poor         1000\n",
      "Hazardous     500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nData Description:\")\n",
    "display(data.describe())\n",
    "\n",
    "print(\"\\nChecking class distribution in 'Air Quality':\")\n",
    "print(data['Air Quality'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n",
      "X_train_scaled shape: (4000, 9)\n",
      "y_train shape: (4000,)\n"
     ]
    }
   ],
   "source": [
    "# 1) Handle Missing Values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 2) Encode the Target Variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['Air Quality Encoded'] = label_encoder.fit_transform(data['Air Quality'])\n",
    "\n",
    "# 3) Split into Features (X) and Target (y)\n",
    "X = data.drop(columns=['Air Quality', 'Air Quality Encoded'])  # drop original and encoded target\n",
    "y = data['Air Quality Encoded']\n",
    "\n",
    "# 4) Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# 5) Scale the Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data preprocessing completed.\")\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\velja_lo6afyb\\.conda\\envs\\lab4env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4428 - loss: 1.1791 - val_accuracy: 0.6875 - val_loss: 0.8157\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7136 - loss: 0.7532 - val_accuracy: 0.8250 - val_loss: 0.5489\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.4982 - val_accuracy: 0.8775 - val_loss: 0.4076\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8725 - loss: 0.3775 - val_accuracy: 0.8875 - val_loss: 0.3357\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8829 - loss: 0.3287 - val_accuracy: 0.8925 - val_loss: 0.2905\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.2857 - val_accuracy: 0.9062 - val_loss: 0.2583\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2483 - val_accuracy: 0.9112 - val_loss: 0.2356\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2236 - val_accuracy: 0.9100 - val_loss: 0.2234\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2135 - val_accuracy: 0.9237 - val_loss: 0.2103\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2144 - val_accuracy: 0.9237 - val_loss: 0.1992\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.1918 - val_accuracy: 0.9200 - val_loss: 0.1938\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1850 - val_accuracy: 0.9262 - val_loss: 0.1875\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1819 - val_accuracy: 0.9325 - val_loss: 0.1841\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9346 - loss: 0.1742 - val_accuracy: 0.9275 - val_loss: 0.1813\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.1649 - val_accuracy: 0.9300 - val_loss: 0.1807\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.1699 - val_accuracy: 0.9312 - val_loss: 0.1753\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1596 - val_accuracy: 0.9312 - val_loss: 0.1760\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.1680 - val_accuracy: 0.9362 - val_loss: 0.1727\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.1507 - val_accuracy: 0.9300 - val_loss: 0.1717\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9354 - loss: 0.1630 - val_accuracy: 0.9275 - val_loss: 0.1706\n",
      "Model 1 training completed.\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(X_train_scaled, y_train, \n",
    "                      epochs=20, \n",
    "                      batch_size=32,\n",
    "                      validation_split=0.2, \n",
    "                      verbose=1)\n",
    "\n",
    "print(\"Model 1 training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Test Loss: 0.16157551109790802\n",
      "Model 1 - Test Accuracy: 0.9430000185966492\n"
     ]
    }
   ],
   "source": [
    "loss1, accuracy1 = model1.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Model 1 - Test Loss:\", loss1)\n",
    "print(\"Model 1 - Test Accuracy:\", accuracy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4578 - loss: 1.2283 - val_accuracy: 0.7237 - val_loss: 0.7091\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7861 - loss: 0.6308 - val_accuracy: 0.8500 - val_loss: 0.4572\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8634 - loss: 0.4223 - val_accuracy: 0.9075 - val_loss: 0.3543\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.3341 - val_accuracy: 0.9137 - val_loss: 0.2981\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2825 - val_accuracy: 0.9225 - val_loss: 0.2648\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2559 - val_accuracy: 0.9200 - val_loss: 0.2460\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2449 - val_accuracy: 0.9275 - val_loss: 0.2279\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2309 - val_accuracy: 0.9212 - val_loss: 0.2184\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1976 - val_accuracy: 0.9275 - val_loss: 0.2083\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1884 - val_accuracy: 0.9250 - val_loss: 0.2005\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.1827 - val_accuracy: 0.9275 - val_loss: 0.1969\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.1818 - val_accuracy: 0.9250 - val_loss: 0.1928\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.1735 - val_accuracy: 0.9312 - val_loss: 0.1882\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1585 - val_accuracy: 0.9300 - val_loss: 0.1836\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1509 - val_accuracy: 0.9300 - val_loss: 0.1810\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1554 - val_accuracy: 0.9350 - val_loss: 0.1744\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1458 - val_accuracy: 0.9375 - val_loss: 0.1733\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1434 - val_accuracy: 0.9300 - val_loss: 0.1755\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1366 - val_accuracy: 0.9325 - val_loss: 0.1693\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1266 - val_accuracy: 0.9337 - val_loss: 0.1665\n",
      "Model 2 training completed.\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='tanh'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train_scaled, y_train, \n",
    "                      epochs=20, \n",
    "                      batch_size=32,\n",
    "                      validation_split=0.2, \n",
    "                      verbose=1)\n",
    "\n",
    "print(\"Model 2 training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 - Test Loss: 0.14880283176898956\n",
      "Model 2 - Test Accuracy: 0.9490000009536743\n"
     ]
    }
   ],
   "source": [
    "loss2, accuracy2 = model2.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Model 2 - Test Loss:\", loss2)\n",
    "print(\"Model 2 - Test Accuracy:\", accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.9856 - val_accuracy: 0.8925 - val_loss: 0.3586\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8916 - loss: 0.3121 - val_accuracy: 0.9137 - val_loss: 0.2230\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.1921 - val_accuracy: 0.9100 - val_loss: 0.2127\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9347 - loss: 0.1699 - val_accuracy: 0.9250 - val_loss: 0.1827\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.1701 - val_accuracy: 0.9262 - val_loss: 0.1871\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1534 - val_accuracy: 0.9325 - val_loss: 0.1688\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1449 - val_accuracy: 0.9325 - val_loss: 0.1704\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1329 - val_accuracy: 0.9325 - val_loss: 0.1697\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1245 - val_accuracy: 0.9350 - val_loss: 0.1673\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1327 - val_accuracy: 0.9375 - val_loss: 0.1568\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1180 - val_accuracy: 0.9275 - val_loss: 0.1709\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1232 - val_accuracy: 0.9362 - val_loss: 0.1611\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1250 - val_accuracy: 0.9362 - val_loss: 0.1598\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9629 - loss: 0.1041 - val_accuracy: 0.9438 - val_loss: 0.1581\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1158 - val_accuracy: 0.9375 - val_loss: 0.1660\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9568 - loss: 0.1107 - val_accuracy: 0.9337 - val_loss: 0.1614\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1023 - val_accuracy: 0.9375 - val_loss: 0.1579\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.0997 - val_accuracy: 0.9400 - val_loss: 0.1667\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1054 - val_accuracy: 0.9375 - val_loss: 0.1605\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1076 - val_accuracy: 0.9275 - val_loss: 0.1824\n",
      "Model 3 training completed.\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='elu'),\n",
    "    layers.Dense(8, activation='elu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(X_train_scaled, y_train, \n",
    "                      epochs=20, \n",
    "                      batch_size=32,\n",
    "                      validation_split=0.2, \n",
    "                      verbose=1)\n",
    "\n",
    "print(\"Model 3 training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 - Test Loss: 0.1589588224887848\n",
      "Model 3 - Test Accuracy: 0.9390000104904175\n"
     ]
    }
   ],
   "source": [
    "loss3, accuracy3 = model3.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Model 3 - Test Loss:\", loss3)\n",
    "print(\"Model 3 - Test Accuracy:\", accuracy3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Test Accuracies:\n",
      "Model 1: 0.9430\n",
      "Model 2: 0.9490\n",
      "Model 3: 0.9390\n"
     ]
    }
   ],
   "source": [
    "models_accuracies = {\n",
    "    \"Model 1\": accuracy1,\n",
    "    \"Model 2\": accuracy2,\n",
    "    \"Model 3\": accuracy3\n",
    "}\n",
    "\n",
    "print(\"Comparison of Test Accuracies:\")\n",
    "for m, acc in models_accuracies.items():\n",
    "    print(f\"{m}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lab4env",
   "language": "python",
   "name": "lab4env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
